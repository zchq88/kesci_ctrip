{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime \n",
    "import sys\n",
    "%matplotlib inline\n",
    "evaluation=pd.read_csv('submit.txt')\n",
    "product_info=pd.read_csv('product_info.txt')\n",
    "product_quantity=pd.read_csv('product_quantity.txt')\n",
    "Mytrain_day=pd.read_csv('Mytrain_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def random_read_train_data(k,table):    \n",
    "    _Mytrain_day=table.take(np.random.permutation(len(table))[:k])   \n",
    "    _features = _Mytrain_day.drop('ciiquantity',axis=1)\n",
    "    _targets = _Mytrain_day['ciiquantity']\n",
    "    _Myfeatures=_features.as_matrix()\n",
    "    _Mytargets=_targets.as_matrix()\n",
    "    _Mytargets.shape[0]\n",
    "    _Mytargets.shape = (_Mytargets.shape[0], 1)\n",
    "    _Mytargets.transpose()\n",
    "    return _Myfeatures,_Mytargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 Loss: 53.5624 time: 0:00:00.189104"
     ]
    }
   ],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):    \n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "in_shape=13\n",
    "epochs=1000\n",
    "batch=50000\n",
    "l_r=0.01\n",
    "x = tf.placeholder(tf.float32, shape=[None, in_shape])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "l1 = add_layer(x, in_shape, 10, activation_function=tf.nn.sigmoid)\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(y - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(l_r).minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())    \n",
    "    # Training cycle\n",
    "for epoch in range(epochs):\n",
    "    start = datetime.now()\n",
    "    #tf_features,tf_targets = cut_train_data(epoch*1000,(epoch+1)*1000)\n",
    "    tf_features,tf_targets = random_read_train_data(batch,Mytrain_day)\n",
    "    tf_features_text,tf_targets_text = random_read_train_data(batch,Mytrain_day)\n",
    "    sess.run(train_step, feed_dict={x: tf_features, y: tf_targets})\n",
    "    temploss = sess.run(loss, feed_dict={x: tf_features_text, y: tf_targets_text})\n",
    "    end = datetime.now()\n",
    "    sys.stdout.write('\\rEpoch {:>2} Loss: {:.4f} time: {}'.format(epoch + 1,temploss,end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getweek(product_date):\n",
    "    yyyy=int(product_date[0:4])\n",
    "    mm=int(product_date[5:7])\n",
    "    dd=int(product_date[8:10])\n",
    "    return datetime(yyyy,mm,dd).weekday()+1\n",
    "\n",
    "def addweekday(table):\n",
    "    table['week']=table['product_date'].apply(getweek)\n",
    "    dummies = pd.get_dummies(table['week'], prefix='week', drop_first=False)\n",
    "    table = pd.concat([table, dummies], axis=1)\n",
    "    table = table.drop('week', axis=1)\n",
    "    table = table.drop('product_date', axis=1)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.54\n",
      "i:31901/56000 ciiquantity month:179.87612915039062 time:0:00:01.886002"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "def get_evaluation(x):\n",
    "    _date=evaluation[evaluation.index==x].product_month.as_matrix()[0]\n",
    "    _id=evaluation[evaluation.index==x].product_id.as_matrix()[0]\n",
    "    _yyyy=int(_date[0:4])\n",
    "    _mm=int(_date[5:7])\n",
    "    _days=calendar.monthrange(_yyyy,_mm)[1]\n",
    "    _table=pd.DataFrame({'product_date':range(_days)})\n",
    "    _table['product_date']=_table['product_date'].apply(lambda x:_date[0:8]+str(x+1).zfill(2))\n",
    "    _table['product_id']=_id\n",
    "    _features=['eval','eval2','eval3','eval4','voters','maxstock']\n",
    "    for feature in _features:\n",
    "        value=product_info[product_info.product_id==_id][feature].as_matrix()[0]\n",
    "        mean, std = product_info[feature].mean(), product_info[feature].std()\n",
    "        value = (value - mean)/std\n",
    "        _table[feature]=value\n",
    "    _table=addweekday(_table)\n",
    "    _table=_table.drop('product_id', axis=1)\n",
    "    #_table=addfeature(_table,_features)\n",
    "    #_table=Scalingfeature(_table,_features)\n",
    "    _table=_table.as_matrix()\n",
    "    return _table\n",
    "y_array=np.sum(sess.run(prediction, feed_dict={x: get_evaluation(0)}))\n",
    "print(y_array)\n",
    "ciiquantity_month=np.zeros(evaluation.shape[0])\n",
    "#'''\n",
    "start = datetime.now()\n",
    "for i in range(evaluation.shape[0]):\n",
    "#for i in range(1000):\n",
    "    _date=evaluation[evaluation.index==i].product_month.as_matrix()[0]\n",
    "    _mm=int(_date[5:7])\n",
    "    \n",
    "    month_data=get_evaluation(i)\n",
    "    month_data_sum=np.sum(sess.run(prediction, feed_dict={x: month_data}))\n",
    "    if(_mm==10):\n",
    "        print(_mm)\n",
    "        ciiquantity_month[i]=month_data_sum*2\n",
    "    else:\n",
    "        ciiquantity_month[i]=month_data_sum*1.2\n",
    "    if i % 100 == 0:\n",
    "        end = datetime.now()        \n",
    "        sys.stdout.write('\\ri:{}/{} ciiquantity month:{} time:{}'.format(i+1,evaluation.shape[0],month_data_sum,end-start))\n",
    "        start = datetime.now()\n",
    "#'''\n",
    "evaluation['ciiquantity_month']=ciiquantity_month\n",
    "evaluation.to_csv('my_ansower_quick_nn.csv',index=False)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
